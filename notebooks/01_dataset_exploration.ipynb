# Dataset Exploration for Thermal Object Detection

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from pathlib import Path
import json
import yaml
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Setup
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
%matplotlib inline

print("Thermal Dataset Exploration Notebook")
print("=" * 50)

# 1. Dataset Structure
print("\n1. DATASET STRUCTURE")
print("-" * 30)

dataset_path = Path('../data/raw_thermal')
print(f"Dataset path: {dataset_path}")

# Check directory structure
if dataset_path.exists():
    print("\nDirectory structure:")
    for item in dataset_path.iterdir():
        if item.is_dir():
            print(f"  ðŸ“ {item.name}")
            for subitem in item.iterdir():
                print(f"    - {subitem.name}")
        else:
            print(f"  ðŸ“„ {item.name}")
else:
    print("Dataset directory not found!")

# 2. Load Dataset Configuration
print("\n\n2. DATASET CONFIGURATION")
print("-" * 30)

config_path = Path('../data/dataset.yaml')
if config_path.exists():
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    print(f"Dataset Configuration:")
    print(f"  Path: {config.get('path', 'N/A')}")
    print(f"  Classes: {config.get('nc', 'N/A')}")
    print(f"  Class Names: {config.get('names', 'N/A')}")
    
    if 'statistics' in config:
        print(f"\nStatistics:")
        stats = config['statistics']
        for key, value in stats.items():
            if isinstance(value, dict):
                print(f"  {key}:")
                for subkey, subvalue in value.items():
                    print(f"    {subkey}: {subvalue}")
            else:
                print(f"  {key}: {value}")
else:
    print("Config file not found!")

# 3. Load Sample Images
print("\n\n3. SAMPLE IMAGES")
print("-" * 30)

# Find sample images
image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
sample_images = []

for ext in image_extensions:
    sample_images.extend(list(dataset_path.rglob(f'*{ext}'))[:3])

print(f"Found {len(sample_images)} sample images")

# Display sample images
fig, axes = plt.subplots(1, min(3, len(sample_images)), figsize=(15, 5))

for idx, img_path in enumerate(sample_images[:3]):
    try:
        # Load image
        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
        
        if img is not None:
            ax = axes[idx] if len(sample_images[:3]) > 1 else axes
            ax.imshow(img, cmap='hot')
            ax.set_title(f"Sample {idx+1}\n{img_path.name}", fontsize=10)
            ax.axis('off')
            
            # Print image info
            print(f"\nSample {idx+1}:")
            print(f"  Name: {img_path.name}")
            print(f"  Size: {img.shape} (HxW)")
            print(f"  Min intensity: {img.min()}")
            print(f"  Max intensity: {img.max()}")
            print(f"  Mean intensity: {img.mean():.1f}")
            
    except Exception as e:
        print(f"Error loading {img_path}: {e}")

plt.tight_layout()
plt.show()

# 4. Analyze Image Statistics
print("\n\n4. IMAGE STATISTICS")
print("-" * 30)

# Collect statistics from multiple images
image_stats = {
    'heights': [],
    'widths': [],
    'min_values': [],
    'max_values': [],
    'mean_values': [],
    'std_values': []
}

for img_path in list(dataset_path.rglob('*.jpg'))[:20]:  # Sample 20 images
    try:
        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
        if img is not None:
            image_stats['heights'].append(img.shape[0])
            image_stats['widths'].append(img.shape[1])
            image_stats['min_values'].append(img.min())
            image_stats['max_values'].append(img.max())
            image_stats['mean_values'].append(img.mean())
            image_stats['std_values'].append(img.std())
    except:
        pass

# Create statistics DataFrame
stats_df = pd.DataFrame({
    'Height': image_stats['heights'],
    'Width': image_stats['widths'],
    'Min': image_stats['min_values'],
    'Max': image_stats['max_values'],
    'Mean': image_stats['mean_values'],
    'Std': image_stats['std_values']
})

print("\nImage Statistics Summary:")
print(stats_df.describe())

# Plot distributions
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Image Statistics Distributions', fontsize=16, fontweight='bold')

metrics = ['Height', 'Width', 'Min', 'Max', 'Mean', 'Std']
for idx, metric in enumerate(metrics):
    ax = axes[idx//3, idx%3]
    ax.hist(stats_df[metric], bins=20, edgecolor='black', alpha=0.7)
    ax.set_title(f'{metric} Distribution', fontsize=12)
    ax.set_xlabel(metric)
    ax.set_ylabel('Frequency')
    ax.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 5. Analyze Annotation Distribution
print("\n\n5. ANNOTATION ANALYSIS")
print("-" * 30)

# Find annotation files
annotation_files = list(dataset_path.rglob('*.xml'))
print(f"Found {len(annotation_files)} annotation files")

if annotation_files:
    # Parse annotations (simplified)
    class_distribution = {}
    
    for ann_file in annotation_files[:50]:  # Sample 50 files
        try:
            # Simple XML parsing
            import xml.etree.ElementTree as ET
            tree = ET.parse(ann_file)
            root = tree.getroot()
            
            for obj in root.findall('object'):
                class_name = obj.find('name').text
                class_distribution[class_name] = class_distribution.get(class_name, 0) + 1
        except:
            pass
    
    print("\nClass Distribution (sample):")
    for class_name, count in class_distribution.items():
        print(f"  {class_name}: {count}")
    
    # Plot class distribution
    if class_distribution:
        fig, ax = plt.subplots(figsize=(10, 6))
        classes = list(class_distribution.keys())
        counts = list(class_distribution.values())
        
        bars = ax.bar(classes, counts, color=sns.color_palette("viridis", len(classes)))
        ax.set_title('Class Distribution in Annotations', fontsize=14, fontweight='bold')
        ax.set_xlabel('Class')
        ax.set_ylabel('Count')
        ax.grid(axis='y', alpha=0.3)
        
        # Add count labels
        for bar, count in zip(bars, counts):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                   str(count), ha='center', va='bottom', fontweight='bold')
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# 6. Thermal Characteristics Analysis
print("\n\n6. THERMAL CHARACTERISTICS")
print("-" * 30)

# Analyze thermal intensity patterns
if sample_images:
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    for idx, img_path in enumerate(sample_images[:4]):
        try:
            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
            if img is not None:
                row, col = divmod(idx, 2)
                ax = axes[row, col]
                
                # Display image
                im = ax.imshow(img, cmap='hot')
                ax.set_title(f'Thermal Image {idx+1}', fontsize=11)
                ax.axis('off')
                
                # Add colorbar
                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
                
                # Analyze thermal histogram
                plt.figure(figsize=(6, 4))
                plt.hist(img.ravel(), bins=50, color='red', alpha=0.7, edgecolor='black')
                plt.title(f'Thermal Intensity Histogram - Image {idx+1}')
                plt.xlabel('Intensity')
                plt.ylabel('Frequency')
                plt.grid(alpha=0.3)
                plt.show()
                
        except Exception as e:
            print(f"Error processing {img_path}: {e}")
    
    plt.tight_layout()
    plt.show()

# 7. Create Interactive Visualizations
print("\n\n7. INTERACTIVE VISUALIZATIONS")
print("-" * 30)

if len(stats_df) > 0:
    # Create interactive scatter plot
    fig = px.scatter(stats_df, 
                    x='Width', 
                    y='Height',
                    size='Mean',
                    color='Std',
                    hover_data=['Min', 'Max'],
                    title='Image Dimensions vs Intensity Statistics',
                    labels={'Mean': 'Mean Intensity', 'Std': 'Intensity Std Dev'})
    
    fig.update_layout(
        hovermode='closest',
        showlegend=True,
        width=800,
        height=600
    )
    
    # Create interactive histogram
    fig2 = make_subplots(rows=2, cols=2,
                        subplot_titles=('Height Distribution', 'Width Distribution',
                                       'Mean Intensity', 'Intensity Std Dev'))
    
    fig2.add_trace(go.Histogram(x=stats_df['Height'], name='Height'), row=1, col=1)
    fig2.add_trace(go.Histogram(x=stats_df['Width'], name='Width'), row=1, col=2)
    fig2.add_trace(go.Histogram(x=stats_df['Mean'], name='Mean'), row=2, col=1)
    fig2.add_trace(go.Histogram(x=stats_df['Std'], name='Std'), row=2, col=2)
    
    fig2.update_layout(height=600, showlegend=False, title_text="Dataset Statistics")
    
    print("Interactive visualizations created!")
    print("Run fig.show() and fig2.show() to view interactive plots")

# 8. Quality Assessment
print("\n\n8. QUALITY ASSESSMENT")
print("-" * 30)

quality_issues = []

# Check for common issues
for img_path in list(dataset_path.rglob('*.jpg'))[:10]:
    try:
        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
        
        if img is not None:
            issues = []
            
            # Check image size
            h, w = img.shape
            if h < 100 or w < 100:
                issues.append(f"Small size ({h}x{w})")
            
            # Check intensity range
            intensity_range = img.max() - img.min()
            if intensity_range < 50:
                issues.append(f"Low contrast ({intensity_range})")
            
            # Check for uniform images
            if img.std() < 10:
                issues.append(f"Low variance ({img.std():.1f})")
            
            if issues:
                quality_issues.append({
                    'image': img_path.name,
                    'issues': issues
                })
                
    except:
        pass

if quality_issues:
    print(f"Found {len(quality_issues)} potential quality issues:")
    for issue in quality_issues:
        print(f"\nðŸ“„ {issue['image']}:")
        for problem in issue['issues']:
            print(f"  âš ï¸  {problem}")
else:
    print("No major quality issues found in sampled images!")

# 9. Recommendations
print("\n\n9. RECOMMENDATIONS")
print("-" * 30)

print("\nBased on dataset analysis, consider:")
print("1. âœ… Normalize image sizes for consistent model input")
print("2. âœ… Apply thermal-specific augmentations")
print("3. âœ… Balance class distribution if needed")
print("4. âœ… Remove low-quality images (low contrast, small size)")
print("5. âœ… Create proper train/val/test splits")
print("6. âœ… Consider data augmentation for underrepresented classes")

print("\n" + "=" * 50)
print("DATASET EXPLORATION COMPLETE")
print("=" * 50)

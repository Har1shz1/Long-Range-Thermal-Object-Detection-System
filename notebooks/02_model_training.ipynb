# Model Training Notebook for Thermal Object Detection

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yaml
import json
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# Add src to path
sys.path.append('..')

# Setup
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
%matplotlib inline

print("Thermal Object Detection - Model Training Notebook")
print("=" * 60)

# 1. Environment Setup
print("\n1. ENVIRONMENT SETUP")
print("-" * 30)

# Check PyTorch version
print(f"PyTorch Version: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA Version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    device = torch.device('cuda')
else:
    print("Using CPU")
    device = torch.device('cpu')

# 2. Load Configuration
print("\n\n2. LOAD TRAINING CONFIGURATION")
print("-" * 30)

config_path = Path('../configs/training_config.yaml')
if config_path.exists():
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    print("Training Configuration:")
    print(json.dumps(config, indent=2))
else:
    print("Config file not found!")
    # Create default config
    config = {
        'model': {'architecture': 'yolov5s', 'pretrained': True},
        'training': {'epochs': 100, 'batch_size': 16, 'learning_rate': 0.001},
        'data': {'image_size': 640}
    }

# 3. Dataset Preparation
print("\n\n3. DATASET PREPARATION")
print("-" * 30)

# Load dataset info
dataset_path = Path('../data/processed/dataset.yaml')
if dataset_path.exists():
    with open(dataset_path, 'r') as f:
        dataset_info = yaml.safe_load(f)
    
    print(f"Dataset Info:")
    print(f"  Classes: {dataset_info.get('nc', 'N/A')}")
    print(f"  Class Names: {dataset_info.get('names', 'N/A')}")
    print(f"  Train Path: {dataset_info.get('train', 'N/A')}")
    print(f"  Val Path: {dataset_info.get('val', 'N/A')}")
else:
    print("Dataset YAML not found!")

# Check dataset structure
train_dir = Path('../data/processed/train/images')
val_dir = Path('../data/processed/val/images')

print(f"\nDataset Structure:")
print(f"  Train images: {len(list(train_dir.glob('*.jpg')))}" if train_dir.exists() else "  Train dir not found")
print(f"  Val images: {len(list(val_dir.glob('*.jpg')))}" if val_dir.exists() else "  Val dir not found")

# 4. Visualize Training Data
print("\n\n4. VISUALIZE TRAINING DATA")
print("-" * 30)

# Load a few training images
train_images = list(train_dir.glob('*.jpg'))[:4]

if train_images:
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('Sample Training Images', fontsize=16, fontweight='bold')
    
    for idx, img_path in enumerate(train_images[:4]):
        try:
            # Load image
            import cv2
            img = cv2.imread(str(img_path))
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # Plot
            row, col = divmod(idx, 2)
            ax = axes[row, col]
            ax.imshow(img_rgb)
            ax.set_title(f'Training Image {idx+1}', fontsize=12)
            ax.axis('off')
            
            # Check for corresponding label
            label_path = img_path.parent.parent / 'labels' / f"{img_path.stem}.txt"
            if label_path.exists():
                with open(label_path, 'r') as f:
                    labels = f.readlines()
                ax.text(10, 30, f"Labels: {len(labels)}", 
                       color='white', fontsize=10,
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.7))
            
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
    
    plt.tight_layout()
    plt.show()
else:
    print("No training images found!")

# 5. Model Architecture
print("\n\n5. MODEL ARCHITECTURE")
print("-" * 30)

# Import YOLOv5 (if available)
try:
    import torch
    import torch.nn as nn
    
    print("YOLOv5 Model Architecture:")
    
    # Simplified YOLO model definition
    class SimpleYOLO(nn.Module):
        def __init__(self, num_classes=3):
            super(SimpleYOLO, self).__init__()
            self.num_classes = num_classes
            
            # Backbone (simplified)
            self.backbone = nn.Sequential(
                nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                
                nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                
                nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
                nn.BatchNorm2d(256),
                nn.ReLU(),
            )
            
            # Head
            self.head = nn.Sequential(
                nn.Conv2d(256, 512, kernel_size=3, padding=1),
                nn.BatchNorm2d(512),
                nn.ReLU(),
                nn.Conv2d(512, (5 + num_classes) * 3, kernel_size=1)  # 3 anchors
            )
        
        def forward(self, x):
            x = self.backbone(x)
            x = self.head(x)
            return x
    
    # Create model instance
    model = SimpleYOLO(num_classes=3)
    
    # Calculate parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"Model: YOLOv5s (Simplified)")
    print(f"Input channels: 3")
    print(f"Number of classes: 3")
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    
    # Print model structure
    print("\nModel Architecture:")
    print(model)
    
except ImportError as e:
    print(f"PyTorch not available: {e}")
    print("Using simulated model for demonstration")

# 6. Training Setup
print("\n\n6. TRAINING SETUP")
print("-" * 30)

# Simulated training configuration
training_config = {
    'optimizer': 'Adam',
    'learning_rate': 0.001,
    'weight_decay': 0.0005,
    'momentum': 0.937,
    'batch_size': 16,
    'epochs': 100,
    'augmentation': {
        'hsv_h': 0.015,
        'hsv_s': 0.7,
        'hsv_v': 0.4,
        'flip_lr': 0.5
    }
}

print("Training Configuration:")
for key, value in training_config.items():
    if isinstance(value, dict):
        print(f"  {key}:")
        for sub_key, sub_value in value.items():
            print(f"    {sub_key}: {sub_value}")
    else:
        print(f"  {key}: {value}")

# 7. Simulated Training Loop
print("\n\n7. SIMULATED TRAINING PROGRESS")
print("-" * 30)

# Generate simulated training metrics
np.random.seed(42)
epochs = 20  # Show first 20 epochs for demo

# Simulated metrics
train_loss = [2.5 - 0.1*i + np.random.randn()*0.05 for i in range(epochs)]
val_loss = [2.3 - 0.08*i + np.random.randn()*0.1 for i in range(epochs)]
val_map = [0.3 + 0.03*i + np.random.randn()*0.02 for i in range(epochs)]
val_map = [min(v, 0.95) for v in val_map]  # Cap at 0.95
learning_rates = [0.001 * (0.95**i) for i in range(epochs)]

# Create training progress visualization
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Training Progress Simulation', fontsize=16, fontweight='bold')

# Plot 1: Training and Validation Loss
ax1 = axes[0, 0]
ax1.plot(range(1, epochs+1), train_loss, 'b-', label='Training Loss', linewidth=2, marker='o')
ax1.plot(range(1, epochs+1), val_loss, 'r-', label='Validation Loss', linewidth=2, marker='s')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss')
ax1.set_title('Training & Validation Loss', fontsize=12, fontweight='bold')
ax1.legend()
ax1.grid(alpha=0.3)
ax1.set_xticks(range(1, epochs+1, 2))

# Plot 2: Validation mAP
ax2 = axes[0, 1]
ax2.plot(range(1, epochs+1), val_map, 'g-', linewidth=2, marker='^')
ax2.axhline(y=0.9, color='r', linestyle='--', alpha=0.5, label='Target: 0.9')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('mAP@0.5')
ax2.set_title('Validation mAP Progress', fontsize=12, fontweight='bold')
ax2.legend()
ax2.grid(alpha=0.3)
ax2.set_ylim(0, 1.0)
ax2.set_xticks(range(1, epochs+1, 2))

# Plot 3: Learning Rate Schedule
ax3 = axes[1, 0]
ax3.plot(range(1, epochs+1), learning_rates, 'purple', linewidth=2, marker='d')
ax3.set_xlabel('Epoch')
ax3.set_ylabel('Learning Rate')
ax3.set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')
ax3.set_yscale('log')
ax3.grid(alpha=0.3)
ax3.set_xticks(range(1, epochs+1, 2))

# Plot 4: Simulated Batch Processing
ax4 = axes[1, 1]
batch_times = np.random.exponential(0.1, 100)  # Simulated batch times
cumulative_time = np.cumsum(batch_times)
ax4.plot(cumulative_time, range(1, 101), 'orange', linewidth=2)
ax4.set_xlabel('Time (seconds)')
ax4.set_ylabel('Batches Processed')
ax4.set_title('Training Throughput', fontsize=12, fontweight='bold')
ax4.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 8. Model Evaluation Simulation
print("\n\n8. MODEL EVALUATION SIMULATION")
print("-" * 30)

# Simulated evaluation metrics
class_metrics = {
    'human': {'precision': 0.963, 'recall': 0.945, 'ap': 0.952},
    'animal': {'precision': 0.921, 'recall': 0.898, 'ap': 0.912},
    'vehicle': {'precision': 0.978, 'recall': 0.961, 'ap': 0.972}
}

overall_metrics = {
    'mAP': 0.945,
    'precision': 0.954,
    'recall': 0.935,
    'f1_score': 0.944,
    'inference_time': 0.085  # seconds
}

print("Overall Metrics:")
for metric, value in overall_metrics.items():
    if metric == 'inference_time':
        print(f"  {metric}: {value*1000:.1f} ms")
    else:
        print(f"  {metric}: {value:.3f}")

print("\nPer-Class Metrics:")
for class_name, metrics in class_metrics.items():
    print(f"  {class_name.upper()}:")
    for metric, value in metrics.items():
        print(f"    {metric}: {value:.3f}")

# Create metrics visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Bar chart for overall metrics
ax1 = axes[0]
overall_metrics_plot = {
    'mAP': overall_metrics['mAP'],
    'Precision': overall_metrics['precision'],
    'Recall': overall_metrics['recall'],
    'F1-Score': overall_metrics['f1_score']
}
bars1 = ax1.bar(overall_metrics_plot.keys(), overall_metrics_plot.values(),
               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFEAA7'])
ax1.set_title('Overall Evaluation Metrics', fontsize=14, fontweight='bold')
ax1.set_ylim(0, 1.0)
ax1.grid(axis='y', alpha=0.3)

# Add value labels
for bar, val in zip(bars1, overall_metrics_plot.values()):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')

# Per-class metrics heatmap
ax2 = axes[1]
metrics_matrix = np.array([
    [class_metrics['human']['precision'], class_metrics['human']['recall'], class_metrics['human']['ap']],
    [class_metrics['animal']['precision'], class_metrics['animal']['recall'], class_metrics['animal']['ap']],
    [class_metrics['vehicle']['precision'], class_metrics['vehicle']['recall'], class_metrics['vehicle']['ap']]
])

im = ax2.imshow(metrics_matrix, cmap='YlOrRd', aspect='auto')
ax2.set_xticks([0, 1, 2])
ax2.set_yticks([0, 1, 2])
ax2.set_xticklabels(['Precision', 'Recall', 'AP'])
ax2.set_yticklabels(['Human', 'Animal', 'Vehicle'])
ax2.set_title('Per-Class Metrics', fontsize=14, fontweight='bold')

# Add text annotations
for i in range(3):
    for j in range(3):
        ax2.text(j, i, f'{metrics_matrix[i, j]:.3f}',
                ha="center", va="center",
                color="white" if metrics_matrix[i, j] > 0.7 else "black",
                fontweight='bold')

plt.colorbar(im, ax=ax2)
plt.tight_layout()
plt.show()

# 9. Training Recommendations
print("\n\n9. TRAINING RECOMMENDATIONS")
print("-" * 30)

print("\nBased on simulation, consider these improvements:")
print("1. ✅ Increase dataset size for animal class")
print("2. ✅ Adjust learning rate schedule")
print("3. ✅ Implement early stopping")
print("4. ✅ Use mixed precision training")
print("5. ✅ Experiment with different optimizers")
print("6. ✅ Add more thermal-specific augmentations")
print("7. ✅ Monitor class-wise performance")
print("8. ✅ Regularize to prevent overfitting")

# 10. Export Model
print("\n\n10. MODEL EXPORT")
print("-" * 30)

print("Model can be exported in multiple formats:")
print("1. PyTorch (.pt) - For further training/fine-tuning")
print("2. ONNX (.onnx) - For interoperability")
print("3. TensorFlow Lite (.tflite) - For edge deployment")
print("4. CoreML (.mlmodel) - For iOS deployment")

export_options = {
    'format': ['PyTorch', 'ONNX', 'TensorFlow Lite', 'CoreML'],
    'size_mb': [14.2, 13.8, 8.5, 9.2],
    'inference_time_ms': [45, 48, 85, 92],
    'compatibility': ['Training', 'Cross-platform', 'Edge devices', 'iOS']
}

export_df = pd.DataFrame(export_options)
print("\nExport Options Comparison:")
print(export_df.to_string(index=False))

print("\n" + "=" * 60)
print("MODEL TRAINING NOTEBOOK COMPLETE")
print("Next steps:")
print("1. Run actual training with: python src/training/train_yolo.py")
print("2. Evaluate on test set")
print("3. Optimize for deployment")
print("=" * 60)
